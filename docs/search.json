[
  {
    "objectID": "processo_linear_geral.html#o-polinômio-de-defasagens",
    "href": "processo_linear_geral.html#o-polinômio-de-defasagens",
    "title": "10  Modelos ARMA",
    "section": "10.1 O polinômio de defasagens",
    "text": "10.1 O polinômio de defasagens\n\nDefinition 10.1 Considere uma sequência \\(\\{a_t\\}\\). O operador defasagem é definido como \\(Ba_t = a_{t-1}\\). Em inglês este operador é conhecido como backshift.\n\n\nExample 10.1 Considere a série \\(11,6,3,7,15,8\\).\n\\[\\begin{align*}\n     Ba_2 &= a_{1}=11\\\\\n     B a_6& =a_5 =15\n    \\end{align*}\\] \\(\\blacksquare\\)\n\nSeguem algumas propriedades fundamentais do operador defasagem\n\n\\(Bc=c\\)\n\\(B^k a_t=a_{t-k}\\).\n\\(B(c+ba_{t-1})=c+bBa_t\\) (operador linear)\n\\((B^m - B^n)a_t = a_{t-m}-a_{t-n}.\\)\n\\(B^{-1}a_t = a_{t+1}\\)\n\nNote que o operador \\(B^{-1}\\) leva \\(a_t\\) para um passo a frente (como em uma previsão). É comum encontrar a definição \\(F=B^{-1}\\), onde a letra \\(F\\) é escolhida por causa do termo (previsão).\n\nExample 10.2 Seja \\(B\\) o operado defasagem. Então, definimos um polinômio de defasagens como \\[\\psi(B)=a_0+a_1B+\\cdots+a_n B^n.\\]\n\nNote que \\(\\psi(B)\\) é um modo sucinto para escrever \\[a(B)x_t=a_0x_t+a_1x_{t-1}+\\cdots+a_n x_{t-n}.\\]\nO polinômio de defasagens pode ser operado como um polinômio regular. Por exemplo, se \\(a(B)=1-aB\\) e \\(b(B)=1-bB\\), fazer \\[\\begin{align}\na(B)b(B)x_t&=a(B)[(1-bB)x_t]=a(B)(x_t-bx_{t-1})\\\\\n&=a(B)x_t-ba(B)x_{t-1}=(1-aB)x_t-b(1-aB)x_{t-1}\\\\\n&=x_t-(a+b)x_{t-1}+abx_{t-2}\\end{align}\\] é equivalente a encontrar \\[c(B)=(1-aB)(1-bB)=1-(a+b)B + abB^2\\] e calcular \\[c(B)x_t=x_t-(a+b)x_{t-1}+abx_{t-2}.\\]\nDizemos que o polinômio de defasagens \\(\\psi(B)\\) possui inversa se existe uma função \\(\\psi^{-1}(B)\\) tal que \\(\\psi(B)\\psi^{-1}(B)x_t=x_t\\).\n\nExample 10.3 Para entender corretamente os modelos que serão propostos, é fundamental entender o que é a inversa do polinômio de defasagens. O caso mais importante, que será a chave para os demais, é o baseado no seguinte polinômio: \\[\\psi(B)=1-\\phi B.\\]\nSuponha que \\[y_t=(1-\\phi B)x_t=x_t-\\phi x_{t-1 }\\] Estamos procurando que qual situação existe \\(\\psi^{-1}(B)\\) tal que \\[x_t=\\psi^{-1}(B)y_t.\\] Como \\[y_{t-1}=(1-\\phi B)x_{t-1}=x_{t-1}-\\phi x_{t-2},\\] teremos que \\[y_t=x_t-\\phi[y_{t-1}-\\phi x_{t-2}]=x_t-\\phi y_{t-1}-\\phi^2x_{t-2}.\\] Note que podemos continuar iterando as equações acima, obtendo \\[y_t=x_t-\\sum_{j=1}^{t-1} \\phi^jy_{t-j}-\\phi^{t}x_0.\\] Assuma que \\(|\\phi|&lt;1\\) e que \\(t\\) é grande, o que implica que \\(\\phi^t x_0\\) é despresível. Então \\[y_t=x_t-\\sum_{j=1}^{t-1}\\phi^j y_{t-j}=x_t-\\sum_{j=1}^{t-1}\\phi^j B^j y_t\\] ou ainda \\[\\left(1-\\sum_{j=1}^{t-1}\\phi^j B^j\\right)y_t=x_t\\] Agora, multiplique os dois lados da equação acima por \\(1-\\phi B\\). Então \\[(1-\\phi B)\\left(1-\\sum_{j=1}^{t-1}\\phi^j B^j\\right)y_t=(1-\\phi B)x_t=y_t \\] Deste modo, \\[\\psi^{-1}(B)=\\lim_{t\\rightarrow \\infty }\\left(1-\\sum_{j=1}^{t}\\phi^j B^j\\right)=1-\\sum_{j=1}^{\\infty}\\phi^j B^j\\]\n\\(\\blacksquare\\)\n\nNo exemplo anterior, o fato de \\(|\\phi|&lt;1\\) garante que a inveresa do polinômio de defasagens existem uma vez que \\(\\lim_{t\\rightarrow\\infty}\\sum_{j=1}^t \\phi^jB^j\\) é convergente.\nO resultado geral é baseado no seguinte teorema.\n\nProposition 10.1 Seja \\(T\\) uma matriz quadrada qualquer e seja \\[S_n=\\sum_{j=1}^n T^j.\\] A série \\(S_n\\) converge quando \\(n\\rightarrow\\infty\\) se e somente se todos os autovalores de \\(T\\) são menores que um em módulo. Nesse caso, \\(T^j\\rightarrow \\textbf{0}\\) quando \\(j\\rightarrow\\infty\\) e \\[S_n\\rightarrow (1-T)^{-1}.\\]\n\nA proposição acima é a chave para demonstrar o seguite teorema\n\nTheorem 10.1 Seja \\[y_t=x_t-\\sum_{j=1}^p\\phi_jx_{t-j}=\\left(1-\\sum_{j=1}^p\\phi_jB^j\\right)x_t=\\phi(B).\\] Então, existe \\(\\phi^{-1}(B)\\) se e somente se o módulo das raízes de \\(\\phi(B)\\) são maiores que um.\n\n\nProof. Faremos a demonstração para o caso \\(p=2\\), mas os mesmos passos podem ser seguidos para demonstrar o caso geral.\nSeja \\[y_t=x_t-\\phi_1x_{t-1}-\\phi_2 x_{t-2}=(1-\\phi_1B-\\phi_2 B^2)x_t.\\] Comecemos notando que\n\\[\\left(\\begin{array}{c} x_t \\\\ x_{t-1}\\end{array}\\right)=\\left(\\begin{array}{c} y_t \\\\ 0\\end{array}\\right)+\\left(\\begin{array}{cc} \\phi_1 & \\phi_2 \\\\ 1 & 0\\end{array}\\right)\\left(\\begin{array}{c} x_{t-1} \\\\ x_{t-2}\\end{array}\\right)\\] Fazendo \\(z_t=(x_t\\;\\;x_{t-1})\\), teremos \\[z_t=\\left(\\begin{array}{c} y_t \\\\ 0\\end{array}\\right)+\\underbrace{\\left(\\begin{array}{cc} \\phi_1 & \\phi_2 \\\\ 1 & 0\\end{array}\\right)}_{A}z_{t-1}.\\] Utilizando essa relação recursiva, teremos \\[z_t=A^t z_{0}+\\sum_{j=0}^{t-1}A^j\\left(\\begin{array}{c} y_{t-j} \\\\ 0\\end{array}\\right)\\] e, notando que \\(x_t=(1\\;\\;0)z_t\\), teremos \\[x_t=(1\\;\\;0)A^t z_{0}+(1\\;\\;0)\\sum_{j=0}^{t-1}A^j\\left(\\begin{array}{c} y_{t-j} \\\\ 0\\end{array}\\right)\\] Suponha que os autovalores de \\(A\\) são, em módulo, maiores que um. Então, pela Proposition 10.1, para \\(t\\) suficientemente grande, \\[\\begin{align}x_t&=(1\\;\\;0)\\sum_{j=1}^\\infty A^j \\left(\\begin{array}{c} y_{t-j} \\\\ 0\\end{array}\\right)=(1\\;\\;0)\\sum_{j=1}^\\infty A^j B^j\\left(\\begin{array}{c} y_{t} \\\\ 0\\end{array}\\right)\\\\&=\\sum_{j=1}^\\infty (1\\;\\;0)A^j B^j\\left(\\begin{array}{c} 1 \\\\ 0\\end{array}\\right)y_{t}=\\phi^{-1}(B)y_t\\end{align}\\] Agora, observe que os autovalores de \\(A\\) são obtidos através da solução de\n\\[\\begin{align}0=&\\left|\\left(\\begin{array}{cc}\\phi_1 & \\phi_2 \\\\ 1 & 0\\end{array}\\right)-\\lambda \\textbf{I}\\right|-\\lambda(\\phi_1-\\lambda)-\\phi_2\\\\&=\\lambda^2-\\lambda \\phi_1-\\phi_2\\\\\n&=1-\\frac{1}{\\lambda}\\phi_1-\\phi_2\\frac{1}{\\lambda^2}\\end{align}\\] Fazendo \\(\\lambda = 1/B\\), teremos que a equação acima se torna \\[0=1-\\frac{1}{\\lambda}\\phi_1-\\phi_2\\frac{1}{\\lambda^2}\\equiv 1-\\phi_1 B-\\phi_2B^2=\\phi(B)\\] logo, se o módulo das raízes de \\(\\phi(B)\\) são maiores que um, então o módulo dos autovalores de \\(A\\) são menores que um e, portanto, existe \\(\\phi^{-1}(B)\\)."
  },
  {
    "objectID": "processo_linear_geral.html#o-modelo-autorregressivo",
    "href": "processo_linear_geral.html#o-modelo-autorregressivo",
    "title": "10  Modelos ARMA",
    "section": "10.2 O modelo autorregressivo",
    "text": "10.2 O modelo autorregressivo\nO modelo autorregressivo de ordem \\(p\\), ou \\(AR(p)\\), é dado por \\[\\begin{equation}\n        y_t = \\sum_{i=1}^{p}\\phi_iy_{t-i} +\\varepsilon_t\n\\end{equation}\\] onde \\(\\{\\varepsilon_t\\}\\) é um ruído branco, tipicamente Normal\\((0,\\nu)\\). Nesse modelo, a contribuição da observação \\(y_{t-j}\\) em \\(y_t\\) é dada por \\(\\phi_j\\), que é invariante no tempo.\nUtilizando o polinômio de defasagens, pode-se escrever o modelo AR(\\(p\\)) como \\[\\begin{equation}\n        \\phi(B)y_t = \\varepsilon_t,\n\\end{equation}\\] onde \\(\\phi(B)=1-B\\phi_1-\\cdots \\phi_p B^p\\). Se o módulo das raízes desse polinômio são maiores que um, então existe \\(\\phi^{-1}(B)\\), ou seja \\[y_t=\\phi^{-1}(B)\\varepsilon_t=\\left(\\sum_{j=1}^\\infty \\psi_jB^j\\right)\\varepsilon_t\\] e o processo será estacionário, com média e variância iguais à \\[\\begin{align}E(y_t)&=\\left(\\sum_{j=1}^\\infty \\psi_jB^j\\right)E(\\varepsilon_t)=0\\\\\nVar(y_t)&=Var\\left(\\sum_{j=1}^\\infty \\psi_jB^j\\varepsilon_t\\right)=\\nu\\sum_{j=1}^\\infty \\psi_j^2\\\\\n\\end{align}\\] e a função de auto covariância é dada por \\[\\begin{align}\n\\gamma(h)&=Cov(y_t,y_{t-h})\\\\&=Cov\\left( \\left(\\sum_{j=1}^\\infty \\psi_jB^j\\right)\\varepsilon_t,\\left(\\sum_{k=1}^\\infty \\psi_kB^k\\right)\\varepsilon_{t-h}\\right)\\\\\n&=\\sum_{j=1}^\\infty \\sum_{k=1}^\\infty \\psi_j\\psi_k Cov\\left(   \\varepsilon_{t-j},\\varepsilon_{t-k-h}\\right)\\\\\n&=\\nu\\sum_{j=1}^\\infty \\psi_j\\psi_{j+h}\\end{align} \\tag{10.1}\\]\n\nExample 10.4 Considere o processo \\(AR(1)\\) abaixo: \\[\\begin{align*}\n    x_t(1-B\\phi)&= \\varepsilon_{t-1}.\n\\end{align*}\\]\nSeja \\(\\dot{B}\\) a raiz do polinômio \\(1-B\\phi\\). Temos que \\[\\begin{align*}\n    \\phi(\\dot{B})=0\\Rightarrow 1-\\phi \\dot{B} =0 \\Rightarrow \\dot{B} =\\frac{1}{\\phi}\n\\end{align*}\\]\nLogo, o processo AR(1) é estacionário se \\[|\\dot{B}|&gt;1\\Rightarrow \\left|\\frac{1}{\\phi}\\right|&gt;1\\Rightarrow |\\phi|&lt; 1\\] Nesse caso, já vimos que \\(\\phi^{-1}(B)=1-\\sum_{j=1}^\\infty\\phi^j B^j\\). Então, pela equação (Equation 10.1), identificando \\(\\psi_j=\\phi^j\\),teremos que\n\\[\\gamma(h)=\\nu\\sum_{j=1}^\\infty \\phi^j\\phi^{j+h}=\\nu\\phi^h\\frac{\\phi^2}{1-\\phi^2} \\] Assim, a função de autocorrelação é dada por \\[\\rho(h)=\\frac{\\gamma(h)}{\\gamma(0)}=\\phi^h.\\]\nNote que:\n\nSe \\(\\phi\\in(0,1)\\), então \\(\\rho(h)\\) decai exponencialmente para zero\nSe \\(\\in(-1,0)\\), então \\(\\rho(h)\\) decai exponencialmente para zero, mas alternando o sinal.\n\n\n\n\n\n\n\\(\\blacksquare\\)\n\n\nExample 10.5 Considere que \\(x_t\\) é um AR(\\(2\\)), ou seja, \\[x_t=\\phi_1 x_{t-1}+\\phi_2 x_{t-2}+\\varepsilon_t=\\phi(B)\\varepsilon_t,\\] onde \\(\\phi(B)=1-\\phi_1B-\\phi_2 B^2\\). As raízes desse polinômio são \\[\\dot{B}=\\frac{1}{2\\phi_2}\\left[\\phi_1\\pm\\sqrt{\\phi_1^2+4\\phi_2}\\right]\\] e, considerando que \\(|\\dot{B}|&gt;1\\), o processo será estacionário se \\((\\phi_1,\\phi_2)\\) pertence ao triângulo delimitado pelos vértices (-2,-1), (0,1), (2,-1). É interessante notarmos que, se \\(\\phi_2&lt;0\\), as raízes de \\(\\phi(B)\\) serão um par de números complexos conjugados.\n\\(\\blacksquare\\)\n\n\n10.2.1 Função de autocorrelação para o \\(AR(p)\\)}\nConsideremos o processo \\[x_t = \\sum_{j=1}^p\\phi_j x_{t-j}+\\varepsilon_t.\\] e suponha que ele é estacionário. Multiplicando ambos os lados por \\(x_{t-h}\\) e aplicando a esperança, teremos \\[\\begin{align}\nE(x_{t-h}x_t)&=\\sum_{j=1}^p \\phi_j E(x_{t-h}x_{\nt-j})\n\\end{align}\\] e, como \\(\\gamma(h)=E(x_t x_{t-h})\\), teremos \\[\\begin{align}\n\\gamma(h)&=\\sum_{j=1}^p \\phi_j \\gamma(h-j)\n\\end{align}\\] Dividindo ambos os lados por \\(\\gamma(0)\\), teremos \\[\\begin{align}\n\\rho(h)&=\\sum_{j=1}^p \\phi_j \\rho(h-j)\n\\end{align}\\] Essa relação pode ser utilizada para encontrar a função de autocorrelação do processo sem a necessidade de encontrar a inversa de \\(\\phi(B)\\).\n\nConsidere o processo \\(AR(2)\\) abaixo: \\[x_{t}=\\phi_1y_{t-1}+\\phi_2y_{t-2}+\\varepsilon_t.\\] Multiplicando a equação acima por \\(x_{t-1}\\) em ambos os lados teremos \\[x_{t}x_{t-1}=\\phi_1x_{t-1}^2+\\phi_2x_{t-2}x_{t-1}+\\varepsilon_t x_{t-1}.\\] Calculando o valor esperado, temos \\[\\begin{align*}\n    \\gamma(1)&=\\phi_1E(x_{t-1}^2)+\\phi_2E(x_{t-2}x_{t-1})+E(\\varepsilon_t x_{t-1})\\\\\n    &=\\phi_1\\gamma(0) + \\phi_2\\gamma(1).\n    \\end{align*}\\] Dividindo ambos os lados por \\(\\gamma(0)\\) teremos \\[\\rho(1)=\\phi_1+\\phi_2\\rho(1),\\] logo, \\[\\rho(1)=\\frac{\\phi_1}{1-\\phi_2}\n\\]\nDe modo análogo, teremos \\[x_{t-2} x_{t}=x_{t-2}\\left(\\phi_1x_{t-1}+\\phi_2x_{t-2}+\\varepsilon_{t}\\right).\\] Aplicando a esperança, teremos \\[\\begin{align*}\n    \\gamma(2)&=\\phi_1 \\gamma(1)+\\phi_2\\gamma(0).\n    \\end{align*}\\] e dividindo os dois lados por \\(\\gamma(0)\\) teremos\n\\[\\rho(2)=\\phi_1\\rho(1)+\\phi_2=\\frac{\\phi_1^2}{1-\\phi_2}+\\phi_2\\] Com os valores de \\(\\rho(1)\\) e \\(\\rho(2)\\), podemos encontrar \\(\\rho(3)\\):\n\\[\\rho(3)=\\phi_1\\rho(2)+\\phi_2\\rho(1)\\] e assim sucessivamente.\n\\(\\blacksquare\\)\n\nEm geral, a função de autocorrelação do processo AR(\\(p\\)) pode ser escrita como\n\\[\\rho(h)=\\sum_{j=1}^p c_j\\left(\\frac{1}{\\dot{B}_j}\\right)^h\\] onde \\(\\dot{B}\\), novamente, é a raiz de \\(\\phi(B)=1-\\sum_{j=1}^p \\phi_j B^j\\).\nVamos mostrar esse resultado para o caso \\(p=2\\) (o caso geral é análogo). Teremos que\n\\[\\begin{align}\n\\left(\\begin{array}{c}\\rho(h)\\\\ \\rho(h-1)\\end{array}\\right)=\\left(\\begin{array}{cc}\\phi_1 & \\phi_2 \\\\ 1 & 0 \\end{array}\\right)\\end{align}\\]\nSegue que a solução geral da Equação (\\ref{eq::acf_arp}), é dada por \n$$\\rho(h)=\\sum_{j=1}^{p}\\alpha_j^h c_j$$\nonde $\\alpha_j=\\ell_j^{-1}$ e $c_j$ é um polinômio com grau igual a multiplicidade da raiz menos um.\n\nNotas:\n\\begin{itemize}\n    \\item As raízes reais se comportam de acordo com o que já foi visto no $AR(1)$.\n    \\item As raízes complexas tem comportamento sazonal decaindo exponencialmente. \n\\end{itemize}\n\\end{frame}"
  }
]